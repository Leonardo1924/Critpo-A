{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cryptography (CC4017) -- Week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that a probability distribution $D$ over a set $S$ can be seen as a deterministic function mapping random coins $C sampled uniformly at random from a set $C$ to $S$. In this case, the probability mass function is defined, for all $S' ∈ S$, as:\n",
    "\n",
    "$$Pr[S=S':S←\\$D] = Pr[S=S':C←\\$C;S←D(C)] = \\frac{\\#\\{C:D(C) =S'\\}}{|C|}$$\n",
    "\n",
    "We abbreviate this, when clear from the context, to Pr[S'].\n",
    "\n",
    "Recall also that the entropy of such a distribution is given by:\n",
    "\n",
    "$$∑_{S'∈ S} −Pr[S']·log2(Pr[S'])$$\n",
    "\n",
    "For example, the entropy associated with a perfect coin flip is $\\frac{-1}{2}·log_2(\\frac{1}{2}) + (−\\frac{1}{2}·log_2(\\frac{1}{2})) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer the following questions**\n",
    "\n",
    "1. Consider S the set of integers in the range 0..250 and note p= 251 is a prime number. Take C to be the set of all bit strings of length 8. Let the distribution D to be defined by the function $D(C) :=C (mod \\ p)$, i.e. takes the remainder of coins C divided by p.\n",
    "    \n",
    "    1.1. Calculate the probability of each value in S to be produced by D.\n",
    "\n",
    "    1.2. Repeat the above considering now the set C to be the set of all bit strings of length 64.\n",
    "    \n",
    "    1.3. Are these distributions uniform? If not, can you think of a way to quantify how distant they are from uniform?\n",
    "\n",
    "> \n",
    ">1.1.\n",
    ">\n",
    "> S = [0,250]\n",
    ">\n",
    "> p = 251\n",
    ">\n",
    "> c = $2^8$ = 256\n",
    ">\n",
    ">$$\n",
    ">\\Pr[S'] = \\begin{cases} \n",
    ">\\frac{2}{256}, & S' \\in \\{0, 1, 3, 4\\} \\\\\n",
    ">\\frac{1}{256}, & \\text{otherwise} \n",
    ">\\end{cases}\n",
    ">$$\n",
    ">\n",
    "> 1.2.\n",
    ">\n",
    "> c = $\\{2^{64}-1\\}$ (set of bit strings of length 8)\n",
    ">\n",
    ">$$\n",
    ">b = \\frac{2^{64}}{251} \\approx 7.35 * 10^{16} \n",
    ">$$ \n",
    ">\n",
    "> - b represents the number of times each value in S appears when we map  all C elements in S using $D(C) = (C) \\ mod \\ 251$.\n",
    ">\n",
    "> - Para alguns valores, este valor será arredondado para cima, então valores em S podem aparecer b ou b−1 vezes.\n",
    ">\n",
    "> **Probability**\n",
    ">\n",
    "> - For the first m values ​​(where m is the number of values ​​that appear exactly b times), we have:\n",
    ">\n",
    "> $$Pr[S'] = \\frac{b}{2^{64}}$$\n",
    ">\n",
    "> - For the remaing values in S, we have:\n",
    ">\n",
    "> $$Pr[S'] = \\frac{b-1}{2^{64}}$$\n",
    ">\n",
    "> 1.3.\n",
    ">\n",
    "> The perfectly uniform distribution where $Pr[S'] = \\frac{1}{251}$,  $\\forall S' ∈ S $ teh entropy would be:\n",
    ">\n",
    ">$$\n",
    ">H = -251 \\times \\frac{1}{251} \\times \\log_2 \\left( \\frac{1}{251} \\right) = \\log_2(251) \\approx 7.97\n",
    ">$$\n",
    ">\n",
    "> The distributions are not uniform. We can use entropy to quantify how distant they are from uniform\n",
    ">\n",
    "> $$\n",
    "> \n",
    ">H = -\\left( 4 \\cdot \\frac{2}{256} \\cdot \\log_2\\left(\\frac{2}{256}\\right) + 247 \\cdot \\frac{1}{256} \\cdot \\log_2\\left(\\frac{1}{256}\\right) \\right) \\approx 7.94\n",
    ">$$\n",
    ">\n",
    "><br>\n",
    ">\n",
    ">$$\n",
    ">H = -\\left( \\sum_{i=0}^{m-1} \\frac{b}{2^{64}} \\cdot \\log_2\\left( \\frac{b}{2^{64}} \\right) + \\sum_{i=m}^{250} \\frac{b - 1}{2^{64}} \\cdot \\log_2\\left( \\frac{b - 1}{2^{64}} \\right) \\right) \\approx 7.98\n",
    ">$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Repeat question #1 but take $p = 2^8$, i.e., a power of 2.\n",
    "\n",
    "> 2.1\n",
    "> \n",
    "> S = [0,250]\n",
    ">\n",
    "> p = $2^8$ = 256\n",
    ">\n",
    "> c = $2^8$ = 256\n",
    ">\n",
    ">$$\n",
    ">\\Pr[S'] = \\frac{1}{256}, S' \\in [0,...,250]\n",
    ">$$\n",
    ">\n",
    "> 2.2\n",
    ">\n",
    "> c = $2^{64}$\n",
    ">\n",
    "> $b = \\frac{2^{64}}{251}$\n",
    ">\n",
    "> $\n",
    "> Pr[S'] = \\frac{b-1}{2^{64}}\n",
    "> $\n",
    ">\n",
    "> 2.3\n",
    ">\n",
    "> If the length of bit strings of c is a multiple of p, then the entropy value will always be the same.\n",
    ">\n",
    "> $\n",
    "> H1 = -251 \\cdot \\frac{1}{256} \\cdot \\log_2\\left( \\frac{1}{256} \\right) \\approx 7.84375\n",
    "> $\n",
    ">\n",
    "> $\n",
    "> H2 = -251 \\cdot \\frac{b-1}{2^{64}} \\cdot \\log_2\\left( \\frac{b-1}{2^{64}} \\right) \\approx 7.84375\n",
    "> $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use **Sage** to compute the entropy of the two distributions referred in questions #1 and #2. Compute also the entropy of the uniform distribution over S.\n",
    "\n",
    "4. Generalize the computations from question #3 in **Sage** to compute the entropy of distribution D when C is the set of bit strings of length k. Check (approximately) what is the smallest k for which the entropy computed in Sage for D which matches the entropy of the uniform distribution over S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION 3\n",
      "-- 1 --\n",
      "Entropy for first distribution: 7.9609375\n",
      "Entropy for second distribution: 7.971543553950772\n",
      "Entropy for the uniform distribution over S: 7.971543553950772\n",
      "-- 2 --\n",
      "Entropy for first distribution: 7.84375\n",
      "Entropy for second distribution: 7.84375\n",
      "\n",
      "QUESTION 4\n",
      "Entropy for 40 :7.971543553944834\n",
      "Entropy for 41 :7.971543553947803\n",
      "Entropy for 42 :7.971543553949287\n",
      "Entropy for 43 :7.9715435539500294\n",
      "Entropy for 44 :7.971543553950402\n",
      "Entropy for 45 :7.971543553950587\n",
      "Entropy for 46 :7.97154355395068\n",
      "Entropy for 47 :7.971543553950726\n",
      "Entropy for 48 :7.971543553950749\n",
      "Entropy for 49 :7.9715435539507595\n",
      "Entropy for 50 :7.971543553950767\n",
      "Entropy for 51 :7.971543553950769\n",
      "Entropy for 52 :7.971543553950771\n",
      "Entropy for 53 :7.971543553950772\n",
      "True for 53\n",
      "Entropy for 54 :7.971543553950772\n",
      "True for 54\n",
      "Entropy for 55 :7.971543553950772\n",
      "True for 55\n",
      "Entropy for 56 :7.971543553950772\n",
      "True for 56\n",
      "Entropy for 57 :7.971543553950772\n",
      "True for 57\n",
      "Entropy for 58 :7.971543553950772\n",
      "True for 58\n",
      "Entropy for 59 :7.971543553950772\n",
      "True for 59\n",
      "Entropy for 60 :7.971543553950772\n",
      "True for 60\n",
      "Entropy for 61 :7.971543553950772\n",
      "True for 61\n",
      "Entropy for 62 :7.971543553950772\n",
      "True for 62\n",
      "Entropy for 63 :7.971543553950772\n",
      "True for 63\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def D(c, p):\n",
    "    return c % p\n",
    "\n",
    "# Function to help calculate the entropy values \n",
    "def entropy_aux(p):\n",
    "    if p <= 0:\n",
    "        return 0\n",
    "    entropy_aux_value = -p * math.log2(p) \n",
    "    return entropy_aux_value\n",
    "\n",
    "print(\"QUESTION 3\")\n",
    "print(\"-- 1 --\")\n",
    "# Entropy for first distribution\n",
    "print(f\"Entropy for first distribution: {5 * entropy_aux(2/256) + 246 * entropy_aux(1/256)}\")\n",
    "\n",
    "# Entropy for second distribution\n",
    "blocks = ((2**64)/251)\n",
    "blocks_plus_one_occurrences = D((2**64)-1, 251)\n",
    "blocks_occurrences = 251-blocks_plus_one_occurrences\n",
    "print(f\"Entropy for second distribution: {blocks_plus_one_occurrences * entropy_aux((blocks + 1)/(2**64)) + blocks_occurrences * entropy_aux(blocks/(2**64))}\")\n",
    "\n",
    "# Entropy for the uniform distribution over S\n",
    "max_entropy =  251*entropy_aux(1/251)\n",
    "print(f\"Entropy for the uniform distribution over S: {max_entropy}\") \n",
    "\n",
    "\n",
    "print(\"-- 2 --\")\n",
    "print(f\"Entropy for first distribution: {251 * entropy_aux(1/256)}\")\n",
    "\n",
    "blocks = ((2**64)/(2**8))\n",
    "print(f\"Entropy for second distribution: {251 * entropy_aux((blocks + 1)/(2**64))}\")\n",
    "\n",
    "print()\n",
    "print(\"QUESTION 4\")\n",
    "ks = range(40, 64)\n",
    "for k in ks:\n",
    "    b = int((2**k)/251)\n",
    "    b_p1_occurrences = int(D((2**k)-1, 251))\n",
    "    b_occurrences = 251-b_p1_occurrences\n",
    "    h = b_p1_occurrences * entropy_aux((b+1)/(2**k)) + b_occurrences * entropy_aux(b/(2**k))\n",
    "    print(f\"Entropy for {k} :{h}\")\n",
    "    if h == max_entropy:\n",
    "        print(f\"True for {k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **hexdump** can be used to extract randomness from **/dev/urandom**. Explain what the following command is doing,and how the different flags influence its behavior.\n",
    "\n",
    "    hexdump -n 32 -e'1/4 \"%0X\" 1 \"\\n\"'/dev/urandom\n",
    "\n",
    "    Implement an alternative command that uses/dev/urandom to create a file with random bytes.\n",
    "\n",
    "    **HINT:** use the shellddcommand.\n",
    "    \n",
    "    Use openSSL to do exactly the same.\n",
    "    \n",
    "    **HINT:** look at commandrand.\n",
    "\n",
    "> This command is extracting 32 bytes of random data from /dev/unrandom.\n",
    ">- n specifies the number of bytes to read.\n",
    ">- e specifies the format of the string\n",
    ">\n",
    "> dd if = /dev/urandom bs = 32 count = 8\n",
    ">\n",
    "> openssl rand -hex 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 - Use openSSL to generate a key pair where private key is protected with a password. \n",
    "\n",
    "openssl genrsa 4096\n",
    "\n",
    "See what happens when you increase/decrease the key size.\n",
    "\n",
    "Investigate how openSSL converts the passphrase into a cryptography key for encryption/wrapping\n",
    "\n",
    "> Effect of increased / decrease in key size:\n",
    ">\n",
    "> Larger key sizes (for example, 4096 bits) increase safety, but also make operations (encryption and decription) slower.\n",
    "> Smaller key sizes are faster but offer less security.\n",
    ">\n",
    "> OpenSSL takes the secret phrase supplied and derives a cryptographic key to it. He used a key derivation function (KDF), typically using algorithms like PBKDF2 to make the process safe against brute force attacks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 - Use openSSL to generate random Diffie-Hellman parameters.\n",
    "\n",
    "openssl dh param 2048\n",
    "\n",
    "See what happens when you increase/decrease the key size. Compare to the previous case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The similarity of RSA, increased key size in DH parameters increases safety, but makes the key change process slower. Comparing a 2048-bit DH key with a smaller one (such as 1024 bits) will show that the largest key provides stronger security but requires more computational power for the exchange process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
